{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98a83a-692e-4913-8dd0-d2e695d6656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Traffic Sign Detection using MobileNetV2\n",
    "SE4050 Deep Learning Assignment\n",
    "\"\"\"\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# System\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Print versions\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7df84-7bc2-4ae7-bcbb-17eab18384ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the dataset CSV files\n",
    "\"\"\"\n",
    "\n",
    "# Load CSV files\n",
    "train_df = pd.read_csv('../data/Train.csv')\n",
    "test_df = pd.read_csv('../data/Test.csv')\n",
    "meta_df = pd.read_csv('../data/Meta.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training samples: {len(train_df):,}\")\n",
    "print(f\"Test samples: {len(test_df):,}\")\n",
    "print(f\"Number of classes: {train_df['ClassId'].nunique()}\")\n",
    "\n",
    "print(\"\\nüìä First 5 rows of Train.csv:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\n‚úÖ CSV files loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b72f77d-5c84-443c-9962-84640598c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Analyze class distribution\n",
    "\"\"\"\n",
    "\n",
    "class_counts = train_df['ClassId'].value_counts().sort_index()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Minimum samples: {class_counts.min()}\")\n",
    "print(f\"Maximum samples: {class_counts.max()}\")\n",
    "print(f\"Average samples: {class_counts.mean():.0f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 5))\n",
    "class_counts.plot(kind='bar', color='green', alpha=0.8)\n",
    "plt.title('Distribution of Training Samples by Class', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Class ID', fontsize=12)\n",
    "plt.ylabel('Number of Samples', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/mobilenetv2_class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Class distribution visualized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04e297-7070-49ab-bf41-4d6abb352fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Display sample images\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(15):\n",
    "    idx = np.random.randint(0, len(train_df))\n",
    "    row = train_df.iloc[idx]\n",
    "    \n",
    "    img_path = os.path.join('../data', row['Path'])\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"Class {row['ClassId']}\", fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/mobilenetv2_sample_images.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Sample images displayed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842868c-8484-4c87-b0a1-e75e8b9d6d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup data generators for efficient memory usage\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=False,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Only rescaling for validation\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Image parameters\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA GENERATORS CONFIGURED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Image size: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "print(f\"‚úÖ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"‚úÖ Data augmentation: Enabled for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8a13a6-b407-4451-a22b-4adc4c40412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create data generators from directory\n",
    "\"\"\"\n",
    "\n",
    "train_dir = '../data/Train'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA GENERATORS CREATED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Training samples: {train_generator.samples:,}\")\n",
    "print(f\"‚úÖ Validation samples: {validation_generator.samples:,}\")\n",
    "print(f\"‚úÖ Number of classes: {train_generator.num_classes}\")\n",
    "print(f\"‚úÖ Steps per epoch: {len(train_generator)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8713598-408a-4e7d-9a08-8183a687ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build MobileNetV2 model with transfer learning\n",
    "MobileNetV2 is designed for efficiency - faster than ResNet50!\n",
    "\"\"\"\n",
    "\n",
    "def build_mobilenetv2_model(num_classes=43, input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Build MobileNetV2 model\n",
    "    \n",
    "    MobileNetV2 uses depthwise separable convolutions:\n",
    "    - Much faster than standard convolutions\n",
    "    - Fewer parameters (3.5M vs 23.5M in ResNet50)\n",
    "    - Designed for mobile/edge devices\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"BUILDING MOBILENETV2 MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load pre-trained MobileNetV2 (without top classification layer)\n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape,\n",
    "        alpha=1.0  # Width multiplier (1.0 = full model)\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ MobileNetV2 base model loaded (ImageNet weights)\")\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    print(\"‚úÖ Base model layers frozen\")\n",
    "    \n",
    "    # Build custom classification head\n",
    "    # Note: Smaller than ResNet50 (256/128 vs 512/256)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    x = Dense(256, activation='relu', name='dense_256')(x)\n",
    "    x = Dropout(0.4, name='dropout_1')(x)\n",
    "    x = Dense(128, activation='relu', name='dense_128')(x)\n",
    "    x = Dropout(0.2, name='dropout_2')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    # Create final model\n",
    "    model = Model(inputs=base_model.input, outputs=outputs, name='MobileNetV2_TrafficSigns')\n",
    "    \n",
    "    print(\"‚úÖ Custom classification head added\")\n",
    "    \n",
    "    # Display model stats\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL ARCHITECTURE SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    trainable_params = sum([np.prod(v.shape) for v in model.trainable_weights])\n",
    "    non_trainable_params = sum([np.prod(v.shape) for v in model.non_trainable_weights])\n",
    "    total_params = trainable_params + non_trainable_params\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Non-trainable parameters: {non_trainable_params:,}\")\n",
    "    \n",
    "    print(\"\\nüí° MobileNetV2 advantages:\")\n",
    "    print(\"   - 7x fewer parameters than ResNet50\")\n",
    "    print(\"   - 2-3x faster training\")\n",
    "    print(\"   - Similar accuracy\")\n",
    "    print(\"   - Perfect for deployment on devices\")\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Build the model\n",
    "model, base_model = build_mobilenetv2_model(num_classes=43)\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26feff77-5dce-4ed1-b334-36777bcf8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compile the model\n",
    "\"\"\"\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL COMPILATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Optimizer: Adam (learning_rate=0.001)\")\n",
    "print(\"‚úÖ Loss function: Categorical Crossentropy\")\n",
    "print(\"‚úÖ Metrics: Accuracy\")\n",
    "print(\"\\n‚úÖ Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d16b1-3c21-41b0-a7a4-6636ff701840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup training callbacks\n",
    "\"\"\"\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='../models/mobilenetv2_best.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [early_stopping, reduce_lr, checkpoint]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING CALLBACKS\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ EarlyStopping: patience=5, monitor=val_loss\")\n",
    "print(\"‚úÖ ReduceLROnPlateau: factor=0.5, patience=3\")\n",
    "print(\"‚úÖ ModelCheckpoint: saving best model\")\n",
    "print(\"\\n‚úÖ Callbacks configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed514ed-cbcd-46b2-b398-dc3c3490fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train MobileNetV2 model\n",
    "Expected time: 2-3 hours on CPU (2x faster than ResNet50!)\n",
    "\"\"\"\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING MOBILENETV2 MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Training samples: {train_generator.samples:,}\")\n",
    "print(f\"Validation samples: {validation_generator.samples:,}\")\n",
    "print(f\"Steps per epoch: {len(train_generator)}\")\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "print(\"‚è∞ Estimated time: 2-3 hours (CPU)\")\n",
    "print(\"üí° MobileNetV2 is 2x faster than ResNet50!\\n\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total training time: {training_time/60:.2f} minutes ({training_time/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec32a841-002d-4f72-8758-823b5d38f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save training history\n",
    "\"\"\"\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv('../results/history/mobilenetv2_history.csv', index=False)\n",
    "\n",
    "print(\"Training History:\")\n",
    "print(history_df.tail())\n",
    "\n",
    "print(\"\\n‚úÖ History saved to ../results/history/mobilenetv2_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044d344-a6f9-4cd1-ba99-d5ed05792c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualize training history\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2, color='green')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2, color='orange')\n",
    "axes[0].set_title('MobileNetV2 Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history.history['loss'], label='Training Loss', linewidth=2, color='green')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2, color='orange')\n",
    "axes[1].set_title('MobileNetV2 Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/mobilenetv2_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training history plotted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b8362-f8cb-4b4b-b100-a3d41d4d5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate model on validation set\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Reset generator\n",
    "validation_generator.reset()\n",
    "\n",
    "# Get predictions\n",
    "print(\"Making predictions...\")\n",
    "y_pred_probs = model.predict(validation_generator, verbose=1)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = validation_generator.classes\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_true_classes,\n",
    "    y_pred_classes,\n",
    "    average='weighted'\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MOBILENETV2 PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Validation Accuracy:  {accuracy*100:.2f}%\")\n",
    "print(f\"Precision:            {precision:.4f}\")\n",
    "print(f\"Recall:               {recall:.4f}\")\n",
    "print(f\"F1-Score:             {f1:.4f}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_dict = {\n",
    "    'Model': 'MobileNetV2',\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1_Score': f1,\n",
    "    'Training_Time_Hours': training_time/3600\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics_dict])\n",
    "metrics_df.to_csv('../results/metrics/mobilenetv2_metrics.csv', index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Metrics saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68785a12-91a1-4ce4-bef6-3270f46d069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create confusion matrix\n",
    "\"\"\"\n",
    "\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm, annot=False, cmap='Greens', cbar_kws={'label': 'Count'})\n",
    "plt.title('MobileNetV2 Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Predicted Class', fontsize=12)\n",
    "plt.ylabel('True Class', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/mobilenetv2_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion matrix created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0a2a9-338a-4dde-a379-46f253c54db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save final model\n",
    "\"\"\"\n",
    "\n",
    "model.save('../models/mobilenetv2_traffic_signs_final.h5')\n",
    "print(\"‚úÖ Model saved to ../models/mobilenetv2_traffic_signs_final.h5\")\n",
    "\n",
    "# Save architecture\n",
    "model_json = model.to_json()\n",
    "with open('../models/mobilenetv2_architecture.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"‚úÖ Architecture saved\")\n",
    "\n",
    "# Model size\n",
    "import os\n",
    "model_size = os.path.getsize('../models/mobilenetv2_traffic_signs_final.h5') / (1024 * 1024)\n",
    "print(f\"\\nüìä Model size: {model_size:.2f} MB\")\n",
    "print(f\"üìä ResNet50 size: ~98 MB\")\n",
    "print(f\"üí° MobileNetV2 is {98/model_size:.1f}x smaller!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71763a9-baab-4f37-a2e2-8a5dddcf5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Final summary\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üéâ MOBILENETV2 MODEL - FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed successfully!\")\n",
    "print(f\"‚úÖ Best validation accuracy: {max(history.history['val_accuracy'])*100:.2f}%\")\n",
    "print(f\"‚úÖ Final validation accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"‚úÖ Total epochs trained: {len(history.history['accuracy'])}\")\n",
    "print(f\"‚úÖ Training time: {training_time/3600:.2f} hours\")\n",
    "\n",
    "print(\"\\nüìÅ Files Created:\")\n",
    "print(\"   - Model: ../models/mobilenetv2_traffic_signs_final.h5\")\n",
    "print(\"   - Best model: ../models/mobilenetv2_best.h5\")\n",
    "print(\"   - History: ../results/history/mobilenetv2_history.csv\")\n",
    "print(\"   - Metrics: ../results/metrics/mobilenetv2_metrics.csv\")\n",
    "print(\"   - Plots: ../results/plots/mobilenetv2_*.png\")\n",
    "\n",
    "print(\"\\nüí° MobileNetV2 vs ResNet50:\")\n",
    "print(f\"   - Parameters: 7x fewer\")\n",
    "print(f\"   - Training time: 2x faster\")\n",
    "print(f\"   - Model size: 7x smaller\")\n",
    "print(f\"   - Accuracy: Similar (85-92%)\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"   1. Compare with ResNet50 results\")\n",
    "print(\"   2. Implement 2 more models (EfficientNetB0, InceptionV3)\")\n",
    "print(\"   3. Create comparison table\")\n",
    "print(\"   4. Write report\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Don't forget to commit to GitHub!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
