{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da7289-fbe8-4a7d-861f-4b8dcfd9d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "\n",
    "DATA_DIR   = Path('../data')     \n",
    "MODELS_DIR = Path('../models')   \n",
    "OUTPUTS_DIR= Path('../outputs')   \n",
    "\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed57048-4ba1-4317-b129-54b86fadc534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "def load_gtsrb_dataset(data_dir=DATA_DIR):\n",
    "    \"\"\"\n",
    "    Load  dataset from directory structure\n",
    "    \n",
    "    Expected structure:\n",
    "    data/\n",
    "    └── Train/\n",
    "        ├── 0/\n",
    "        ├── 1/\n",
    "        └── ... (up to 42)\n",
    "\n",
    "    Download: https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING  DATASET\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    train_path = Path(data_dir) / 'Train'\n",
    "    if not train_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset not found at {train_path}!\\n\"\n",
    "            \"Please download GTSRB and extract so that 'data/Train/<class>/*' exists.\"\n",
    "        )\n",
    "    \n",
    "    classes = sorted([d for d in os.listdir(train_path) if (train_path / d).is_dir()])\n",
    "    print(f\"Found {len(classes)} classes\")\n",
    "    \n",
    "    for class_num in classes:\n",
    "        class_path = train_path / class_num\n",
    "        class_images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.ppm'))]\n",
    "        \n",
    "        for img_name in class_images:\n",
    "            img_path = class_path / img_name\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                images.append(img)\n",
    "                labels.append(int(class_num))\n",
    "        \n",
    "        if int(class_num) % 10 == 0:\n",
    "            print(f\"  Loaded class {class_num}...\")\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    print(f\"\\n✓ Successfully loaded {len(images)} images\")\n",
    "    print(f\"✓ Example image shape: {images[0].shape} (will be resized)\")\n",
    "    print(f\"✓ Number of classes: {len(np.unique(labels))}\")\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51426271-c68c-4b98-a1d3-5f9c3e60065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def preprocess_data(images, labels, img_size=32):\n",
    "    \"\"\"\n",
    "    Preprocess images for MLP training\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PREPROCESSING DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"Resizing images to {img_size}x{img_size}...\")\n",
    "    resized_images = np.array([cv2.resize(img, (img_size, img_size)) for img in images])\n",
    "    \n",
    "    print(\"Normalizing pixel values...\")\n",
    "    normalized_images = resized_images.astype('float32') / 255.0\n",
    "    \n",
    "    print(\"Flattening images...\")\n",
    "    flattened_images = normalized_images.reshape(len(normalized_images), -1)\n",
    "    \n",
    "    n_classes = len(np.unique(labels))\n",
    "    labels_categorical = to_categorical(labels, n_classes)\n",
    "    \n",
    "    print(f\"\\n✓ Preprocessed shape: {flattened_images.shape}\")\n",
    "    print(f\"✓ Each image: {img_size}x{img_size}x3 = {flattened_images.shape[1]} features\")\n",
    "    print(f\"✓ Labels shape: {labels_categorical.shape}\")\n",
    "    return flattened_images, labels_categorical, n_classes, normalized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83329c7f-2d36-4366-8095-1732a2a380de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3:  DATA ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def visualize_samples(images, labels, n_samples=20):\n",
    "    \"\"\"\n",
    "    Display random sample images from dataset\n",
    "    \"\"\"\n",
    "    print(\"\\nVisualizing sample images...\")\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "    fig.suptitle('Sample Traffic Signs from Dataset', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    indices = np.random.choice(len(images), n_samples, replace=False)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        idx = indices[i]\n",
    "        ax.imshow(images[idx])\n",
    "        label = np.argmax(labels[idx]) if len(getattr(labels[idx], \"shape\", ())) > 0 else labels[idx]\n",
    "        ax.set_title(f'Class: {label}', fontsize=11)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUTS_DIR / 'samples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_class_distribution(labels):\n",
    "    \"\"\"\n",
    "    Show distribution of traffic sign classes\n",
    "    \"\"\"\n",
    "    print(\"\\nPlotting class distribution...\")\n",
    "    if len(getattr(labels, \"shape\", ())) > 1:\n",
    "        class_counts = np.argmax(labels, axis=1)\n",
    "    else:\n",
    "        class_counts = labels\n",
    "    \n",
    "    plt.figure(figsize=(16, 5))\n",
    "    unique, counts = np.unique(class_counts, return_counts=True)\n",
    "    plt.bar(unique, counts, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Traffic Sign Class', fontsize=13)\n",
    "    plt.ylabel('Number of Images', fontsize=13)\n",
    "    plt.title('Distribution of Traffic Sign Classes in Dataset', fontsize=15, fontweight='bold')\n",
    "    plt.xticks(unique)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    for i, (cls, cnt) in enumerate(zip(unique, counts)):\n",
    "        if i % 3 == 0:\n",
    "            plt.text(cls, cnt + max(5, int(0.01 * counts.max())), str(cnt), ha='center', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUTS_DIR / 'class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ Class distribution plotted\")\n",
    "    print(f\"  Min samples per class: {counts.min()}\")\n",
    "    print(f\"  Max samples per class: {counts.max()}\")\n",
    "    print(f\"  Average samples per class: {counts.mean():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85100a84-84aa-4d87-a76c-a823c28463a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: BUILD MLP MODEL\n",
    "# ============================================================================\n",
    "\n",
    "def build_mlp_model(input_shape, n_classes):\n",
    "    \"\"\"\n",
    "    Build Multi-Layer Perceptron architecture:\n",
    "    512 → 256 → 128 → n_classes\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BUILDING MLP MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(input_shape,), name='hidden_layer_1'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(256, activation='relu', name='hidden_layer_2'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Dense(128, activation='relu', name='hidden_layer_3'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Dense(n_classes, activation='softmax', name='output_layer')\n",
    "    ], name='Traffic_Sign_MLP')\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    print(\"\\n✓ Model built successfully\")\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
